bash-4.1$ spark-submit --class com.log.impl.LogParsingUsingDOM /usr/tmp/denmork/log-processing-0.0.1-SNAPSHOT.jar /usr/tmp/denmork/header /usr/tmp/denmork/output /usr/tmp/denmork/AOLLogger_US_FlatAOL.log/AOLLogger_US_FlatAOL1.log ";" "|"
17/05/24 18:29:11 INFO spark.SparkContext: Running Spark version 1.6.0
17/05/24 18:29:11 INFO spark.SecurityManager: Changing view acls to: x05311
17/05/24 18:29:11 INFO spark.SecurityManager: Changing modify acls to: x05311
17/05/24 18:29:11 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(x05311); users with modify permissions: Set(x05311)
17/05/24 18:29:12 INFO util.Utils: Successfully started service 'sparkDriver' on port 35399.
17/05/24 18:29:12 INFO slf4j.Slf4jLogger: Slf4jLogger started
17/05/24 18:29:12 INFO Remoting: Starting remoting
17/05/24 18:29:12 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@169.172.87.108:38548]
17/05/24 18:29:12 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@169.172.87.108:38548]
17/05/24 18:29:12 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 38548.
17/05/24 18:29:12 INFO spark.SparkEnv: Registering MapOutputTracker
17/05/24 18:29:12 INFO spark.SparkEnv: Registering BlockManagerMaster
17/05/24 18:29:12 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-d4ada0d5-2c78-4e72-8221-5945bf739730
17/05/24 18:29:12 INFO storage.MemoryStore: MemoryStore started with capacity 530.0 MB
17/05/24 18:29:12 INFO spark.SparkEnv: Registering OutputCommitCoordinator
17/05/24 18:29:13 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
17/05/24 18:29:13 INFO ui.SparkUI: Started SparkUI at http://169.172.87.108:4040
17/05/24 18:29:13 INFO spark.SparkContext: Added JAR file:/usr/tmp/denmork/log-processing-0.0.1-SNAPSHOT.jar at spark://169.172.87.108:35399/jars/log-processing-0.0.1-SNAPSHOT.jar with timestamp 1495664953063
17/05/24 18:29:13 INFO client.RMProxy: Connecting to ResourceManager at vm-45k-dd12.usa.net/100.00.002.437:8032
17/05/24 18:29:13 INFO yarn.Client: Requesting a new application from cluster with 4 NodeManagers
17/05/24 18:29:13 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (16384 MB per container)
17/05/24 18:29:13 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
17/05/24 18:29:13 INFO yarn.Client: Setting up container launch context for our AM
17/05/24 18:29:13 INFO yarn.Client: Setting up the launch environment for our AM container
17/05/24 18:29:13 INFO yarn.Client: Preparing resources for our AM container
17/05/24 18:29:14 INFO yarn.Client: Uploading resource file:/tmp/spark-22699fce-b0d7-4671-804d-d5be3c3197bd/__spark_conf__5496266694089101693.zip -> hdfs://vm-45k-dd12.usa.net:8020/user/x05311/.sparkStaging/application_1495610968612_0512/__spark_conf__5496266694089101693.zip
17/05/24 18:29:15 INFO spark.SecurityManager: Changing view acls to: x05311
17/05/24 18:29:15 INFO spark.SecurityManager: Changing modify acls to: x05311
17/05/24 18:29:15 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(x05311); users with modify permissions: Set(x05311)
17/05/24 18:29:15 INFO yarn.Client: Submitting application 512 to ResourceManager
17/05/24 18:29:15 INFO impl.YarnClientImpl: Submitted application application_1495610968612_0512
17/05/24 18:29:16 INFO yarn.Client: Application report for application_1495610968612_0512 (state: ACCEPTED)
17/05/24 18:29:16 INFO yarn.Client:
         client token: N/A
         diagnostics: N/A
         ApplicationMaster host: N/A
         ApplicationMaster RPC port: -1
         queue: root.users.x05311
         start time: 1495664955253
         final status: UNDEFINED
         tracking URL: http://vm-45k-dd12.usa.net:8088/proxy/application_1495610968612_0512/
         user: x05311
17/05/24 18:29:17 INFO yarn.Client: Application report for application_1495610968612_0512 (state: ACCEPTED)
17/05/24 18:29:18 INFO yarn.Client: Application report for application_1495610968612_0512 (state: ACCEPTED)
17/05/24 18:29:19 INFO yarn.Client: Application report for application_1495610968612_0512 (state: ACCEPTED)
17/05/24 18:29:20 INFO yarn.Client: Application report for application_1495610968612_0512 (state: ACCEPTED)
17/05/24 18:29:20 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null)
17/05/24 18:29:20 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> vm-45k-dd12.usa.net, PROXY_URI_BASES -> http://vm-45k-dd12.usa.net:8088/proxy/application_1495610968612_0512), /proxy/application_1495610968612_0512
17/05/24 18:29:20 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
17/05/24 18:29:21 INFO yarn.Client: Application report for application_1495610968612_0512 (state: RUNNING)
17/05/24 18:29:21 INFO yarn.Client:
         client token: N/A
         diagnostics: N/A
         ApplicationMaster host: 100.00.002.437
         ApplicationMaster RPC port: 0
         queue: root.users.x05311
         start time: 1495664955253
         final status: UNDEFINED
         tracking URL: http://vm-45k-dd12.usa.net:8088/proxy/application_1495610968612_0512/
         user: x05311
17/05/24 18:29:21 INFO cluster.YarnClientSchedulerBackend: Application application_1495610968612_0512 has started running.
17/05/24 18:29:21 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37671.
17/05/24 18:29:21 INFO netty.NettyBlockTransferService: Server created on 37671
17/05/24 18:29:21 INFO storage.BlockManager: external shuffle service port = 7337
17/05/24 18:29:21 INFO storage.BlockManagerMaster: Trying to register BlockManager
17/05/24 18:29:21 INFO storage.BlockManagerMasterEndpoint: Registering block manager 169.172.87.108:37671 with 530.0 MB RAM, BlockManagerId(driver, 169.172.87.108, 37671)
17/05/24 18:29:21 INFO storage.BlockManagerMaster: Registered BlockManager
17/05/24 18:29:21 INFO scheduler.EventLoggingListener: Logging events to hdfs://vm-45k-dd12.usa.net:8020/user/spark/applicationHistory/application_1495610968612_0512
17/05/24 18:29:21 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
17/05/24 18:29:22 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 271.8 KB, free 271.8 KB)
17/05/24 18:29:22 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 295.1 KB)
17/05/24 18:29:22 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 169.172.87.108:37671 (size: 23.3 KB, free: 530.0 MB)
17/05/24 18:29:22 INFO spark.SparkContext: Created broadcast 0 from textFile at LogParsingUsingDOM.scala:41
17/05/24 18:29:22 INFO mapred.FileInputFormat: Total input paths to process : 0
17/05/24 18:29:22 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 271.9 KB, free 567.0 KB)
17/05/24 18:29:22 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.3 KB, free 590.3 KB)
17/05/24 18:29:22 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 169.172.87.108:37671 (size: 23.3 KB, free: 530.0 MB)
17/05/24 18:29:22 INFO spark.SparkContext: Created broadcast 1 from textFile at LogParsingUsingDOM.scala:107
17/05/24 18:29:22 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 169.172.87.108:37671 in memory (size: 23.3 KB, free: 530.0 MB)
17/05/24 18:29:22 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/05/24 18:29:22 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/05/24 18:29:22 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/05/24 18:29:22 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/05/24 18:29:22 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/05/24 18:29:22 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
17/05/24 18:29:22 INFO mapred.FileInputFormat: Total input paths to process : 1
17/05/24 18:29:22 INFO spark.SparkContext: Starting job: saveAsTextFile at LogParsingUsingDOM.scala:116
17/05/24 18:29:22 INFO scheduler.DAGScheduler: Got job 0 (saveAsTextFile at LogParsingUsingDOM.scala:116) with 2 output partitions
17/05/24 18:29:22 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (saveAsTextFile at LogParsingUsingDOM.scala:116)
17/05/24 18:29:22 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/05/24 18:29:22 INFO scheduler.DAGScheduler: Missing parents: List()
17/05/24 18:29:22 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at saveAsTextFile at LogParsingUsingDOM.scala:116), which has no missing parents
17/05/24 18:29:23 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 74.0 KB, free 369.2 KB)
17/05/24 18:29:23 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 26.9 KB, free 396.1 KB)
17/05/24 18:29:23 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 169.172.87.108:37671 (size: 26.9 KB, free: 530.0 MB)
17/05/24 18:29:23 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
17/05/24 18:29:23 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at saveAsTextFile at LogParsingUsingDOM.scala:116)
17/05/24 18:29:23 INFO cluster.YarnScheduler: Adding task set 0.0 with 2 tasks
17/05/24 18:29:24 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)
17/05/24 18:29:25 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)
17/05/24 18:29:29 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sd-k2d-62fa.usa.net:43930) with ID 1
17/05/24 18:29:29 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, sd-k2d-62fa.usa.net, partition 0,NODE_LOCAL, 2238 bytes)
17/05/24 18:29:29 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1)
17/05/24 18:29:29 INFO storage.BlockManagerMasterEndpoint: Registering block manager sd-k2d-62fa.usa.net:44225 with 530.0 MB RAM, BlockManagerId(1, sd-k2d-62fa.usa.net, 44225)
17/05/24 18:29:30 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on sd-k2d-62fa.usa.net:44225 (size: 26.9 KB, free: 530.0 MB)
17/05/24 18:29:30 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on sd-k2d-62fa.usa.net:44225 (size: 23.3 KB, free: 530.0 MB)
17/05/24 18:29:31 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, sd-k2d-62fa.usa.net, partition 1,NODE_LOCAL, 2238 bytes)
17/05/24 18:29:31 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0, sd-k2d-62fa.usa.net): java.lang.ArrayIndexOutOfBoundsException: 4
        at com.log.impl.LogParsingUsingDOM$.com$log$impl$LogParsingUsingDOM$$parseLog$1(LogParsingUsingDOM.scala:59)
        at com.log.impl.LogParsingUsingDOM$$anonfun$1.apply(LogParsingUsingDOM.scala:109)
        at com.log.impl.LogParsingUsingDOM$$anonfun$1.apply(LogParsingUsingDOM.scala:109)
        at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
        at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:285)
        at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:171)
        at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:78)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
        at org.apache.spark.scheduler.Task.run(Task.scala:89)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)

17/05/24 18:29:31 INFO storage.BlockManagerInfo: Added rdd_4_1 in memory on sd-k2d-62fa.usa.net:44225 (size: 16.0 B, free: 530.0 MB)
17/05/24 18:29:31 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 0.0 (TID 2, sd-k2d-62fa.usa.net, partition 0,NODE_LOCAL, 2238 bytes)
17/05/24 18:29:32 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 352 ms on sd-k2d-62fa.usa.net (1/2)
17/05/24 18:29:32 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (vm-t12y45-u01.usa.net:57810) with ID 2
17/05/24 18:29:32 INFO scheduler.TaskSetManager: Lost task 0.1 in stage 0.0 (TID 2) on executor sd-k2d-62fa.usa.net: java.lang.ArrayIndexOutOfBoundsException (4) [duplicate 1]
17/05/24 18:29:32 INFO scheduler.TaskSetManager: Starting task 0.2 in stage 0.0 (TID 3, vm-t12y45-u01.usa.net, partition 0,NODE_LOCAL, 2238 bytes)
17/05/24 18:29:32 INFO spark.ExecutorAllocationManager: New executor 2 has registered (new total is 2)
17/05/24 18:29:32 INFO storage.BlockManagerMasterEndpoint: Registering block manager vm-t12y45-u01.usa.net:46065 with 530.0 MB RAM, BlockManagerId(2, vm-t12y45-u01.usa.net, 46065)
17/05/24 18:29:32 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on vm-t12y45-u01.usa.net:46065 (size: 26.9 KB, free: 530.0 MB)
17/05/24 18:29:33 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on vm-t12y45-u01.usa.net:46065 (size: 23.3 KB, free: 530.0 MB)
17/05/24 18:29:34 INFO scheduler.TaskSetManager: Lost task 0.2 in stage 0.0 (TID 3) on executor vm-t12y45-u01.usa.net: java.lang.ArrayIndexOutOfBoundsException (4) [duplicate 2]
17/05/24 18:29:34 INFO scheduler.TaskSetManager: Starting task 0.3 in stage 0.0 (TID 4, sd-k2d-62fa.usa.net, partition 0,NODE_LOCAL, 2238 bytes)
17/05/24 18:29:34 INFO scheduler.TaskSetManager: Lost task 0.3 in stage 0.0 (TID 4) on executor sd-k2d-62fa.usa.net: java.lang.ArrayIndexOutOfBoundsException (4) [duplicate 3]
17/05/24 18:29:34 ERROR scheduler.TaskSetManager: Task 0 in stage 0.0 failed 4 times; aborting job
17/05/24 18:29:34 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool
17/05/24 18:29:34 INFO cluster.YarnScheduler: Cancelling stage 0
17/05/24 18:29:34 INFO scheduler.DAGScheduler: ResultStage 0 (saveAsTextFile at LogParsingUsingDOM.scala:116) failed in 11.345 s
17/05/24 18:29:34 INFO scheduler.DAGScheduler: Job 0 failed: saveAsTextFile at LogParsingUsingDOM.scala:116, took 11.804850 s
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 4, sd-k2d-62fa.usa.net): java.lang.ArrayIndexOutOfBoundsException: 4
        at com.log.impl.LogParsingUsingDOM$.com$log$impl$LogParsingUsingDOM$$parseLog$1(LogParsingUsingDOM.scala:59)
        at com.log.impl.LogParsingUsingDOM$$anonfun$1.apply(LogParsingUsingDOM.scala:109)
        at com.log.impl.LogParsingUsingDOM$$anonfun$1.apply(LogParsingUsingDOM.scala:109)
        at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
        at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:285)
        at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:171)
        at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:78)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
        at org.apache.spark.scheduler.Task.run(Task.scala:89)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
        at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
        at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)
        at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
        at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)
        at org.apache.spark.SparkContext.runJob(SparkContext.scala:1843)
        at org.apache.spark.SparkContext.runJob(SparkContext.scala:1856)
        at org.apache.spark.SparkContext.runJob(SparkContext.scala:1933)
        at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1213)
        at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1156)
        at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1156)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
        at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
        at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1156)
        at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1060)
        at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1026)
        at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1026)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
        at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
        at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)
        at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:952)
        at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:952)
        at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:952)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
        at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
        at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:951)
        at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1457)
        at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1436)
        at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1436)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
        at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
        at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1436)
        at com.log.impl.LogParsingUsingDOM$.main(LogParsingUsingDOM.scala:116)
        at com.log.impl.LogParsingUsingDOM.main(LogParsingUsingDOM.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)
        at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181)
        at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 4
        at com.log.impl.LogParsingUsingDOM$.com$log$impl$LogParsingUsingDOM$$parseLog$1(LogParsingUsingDOM.scala:59)
        at com.log.impl.LogParsingUsingDOM$$anonfun$1.apply(LogParsingUsingDOM.scala:109)
        at com.log.impl.LogParsingUsingDOM$$anonfun$1.apply(LogParsingUsingDOM.scala:109)
        at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
        at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:285)
        at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:171)
        at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:78)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
        at org.apache.spark.scheduler.Task.run(Task.scala:89)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
17/05/24 18:29:34 INFO spark.SparkContext: Invoking stop() from shutdown hook
17/05/24 18:29:34 INFO ui.SparkUI: Stopped Spark web UI at http://169.172.87.108:4040
17/05/24 18:29:35 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
17/05/24 18:29:35 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread
17/05/24 18:29:35 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down
17/05/24 18:29:35 INFO cluster.YarnClientSchedulerBackend: Stopped
17/05/24 18:29:35 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/05/24 18:29:35 INFO storage.MemoryStore: MemoryStore cleared
17/05/24 18:29:35 INFO storage.BlockManager: BlockManager stopped
17/05/24 18:29:35 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
17/05/24 18:29:35 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/05/24 18:29:35 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/05/24 18:29:35 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/05/24 18:29:35 INFO spark.SparkContext: Successfully stopped SparkContext
17/05/24 18:29:35 INFO util.ShutdownHookManager: Shutdown hook called
17/05/24 18:29:35 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-22699fce-b0d7-4671-804d-d5be3c3197bd
